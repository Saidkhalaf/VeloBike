{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T16:58:51.484734Z",
     "start_time": "2024-11-03T16:58:41.412608Z"
    }
   },
   "source": [
    "import ConnectionConfig as cc\n",
    "\n",
    "# Set up the environment and start Spark session\n",
    "cc.setupEnvironment()\n",
    "spark = cc.startLocalCluster(\"DIM_WEATHER\", 4)\n",
    "spark.getActiveSession()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2bd560f9550>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DIM_WEATHER</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:58:53.569465Z",
     "start_time": "2024-11-03T16:58:51.505348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read CSV file with weather data\n",
    "df_weather = spark.read.csv(\"./FileStore/tables/weather.csv\", header=True, inferSchema=True)\n",
    "df_weather.show()"
   ],
   "id": "fb1d4d955d022e86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+------------+\n",
      "|weather_id| temperature|condition|weather_type|\n",
      "+----------+------------+---------+------------+\n",
      "|         1|        >=15|    Sunny|    pleasant|\n",
      "|         2|         <15|    Rainy|  unpleasant|\n",
      "|         3|<15 and >-10|   Cloudy|     natural|\n",
      "|         4|         any|  unknown|     unknown|\n",
      "+----------+------------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:59:00.403733Z",
     "start_time": "2024-11-03T16:58:53.624948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Transform Data:\n",
    "# Transform columns if needed, for example, renaming for clarity\n",
    "dimWeather = df_weather.withColumnRenamed(\"weather_id\", \"weatherSK\") \\\n",
    "    .withColumnRenamed(\"temperature\", \"temperature_condition\") \\\n",
    "    .withColumnRenamed(\"condition\", \"weather_condition\") \\\n",
    "    .withColumnRenamed(\"weather_type\", \"weather_category\")\n",
    "\n",
    "# Define path for the Delta table\n",
    "weather_delta_path = \"spark-warehouse/dimWeather\"\n",
    "# Save dimWeather DataFrame as a Delta table\n",
    "dimWeather.write.format(\"delta\").mode(\"overwrite\").save(weather_delta_path)\n",
    "\n",
    "# Show transformed DataFrame\n",
    "dimWeather.show()"
   ],
   "id": "d2109df5ad1f2a89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+-----------------+----------------+\n",
      "|weatherSK|temperature_condition|weather_condition|weather_category|\n",
      "+---------+---------------------+-----------------+----------------+\n",
      "|        1|                 >=15|            Sunny|        pleasant|\n",
      "|        2|                  <15|            Rainy|      unpleasant|\n",
      "|        3|         <15 and >-10|           Cloudy|         natural|\n",
      "|        4|                  any|          unknown|         unknown|\n",
      "+---------+---------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:59:00.621266Z",
     "start_time": "2024-11-03T16:59:00.440044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create or replace the temporary view for weather dimension\n",
    "dimWeather.createOrReplaceTempView(\"dimWeather\")\n",
    "\n",
    "# Display the dimension table\n",
    "spark.sql(\"SELECT * FROM dimWeather\").show()\n"
   ],
   "id": "4f411a2a2a3011e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+-----------------+----------------+\n",
      "|weatherSK|temperature_condition|weather_condition|weather_category|\n",
      "+---------+---------------------+-----------------+----------------+\n",
      "|        1|                 >=15|            Sunny|        pleasant|\n",
      "|        2|                  <15|            Rainy|      unpleasant|\n",
      "|        3|         <15 and >-10|           Cloudy|         natural|\n",
      "|        4|                  any|          unknown|         unknown|\n",
      "+---------+---------------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:59:04.162660Z",
     "start_time": "2024-11-03T16:59:00.657956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Write DataFrame to Delta table\n",
    "dimWeather.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"dimWeather\")\n"
   ],
   "id": "10921355da37f524",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:59:04.456146Z",
     "start_time": "2024-11-03T16:59:04.180263Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "ce1c1609877bfe87",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
