{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T16:31:14.483718Z",
     "start_time": "2024-11-03T16:31:13.713750Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "import ConnectionConfig as cc\n",
    "cc.setupEnvironment()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:31:33.161054Z",
     "start_time": "2024-11-03T16:31:14.498380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This sets up a local cluster with 4 nodes and retrieve the active spark session\n",
    "spark = cc.startLocalCluster(\"DIM_DATE\",4)\n",
    "spark.getActiveSession()"
   ],
   "id": "a94fcad35b5d75ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2470d18c510>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DIM_DATE</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:31:51.139830Z",
     "start_time": "2024-11-03T16:31:36.446379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Generate a data Sequence \n",
    "#This SQL statement generates a sequence of dates between beginDate and endDate with an increment of 1 day.\n",
    "#dateSK using monotonically_increasing_id() is good for creating a surrogate key.\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "beginDate = '2009-01-01'\n",
    "endDate = '2023-12-31'\n",
    "\n",
    "df_SQL = spark.sql(f\"select explode(sequence(to_date('{beginDate}'), to_date('{endDate}'), interval 1 day)) as calendarDate, monotonically_increasing_id() as dateSK \")\n",
    "\n",
    "\n",
    "df_SQL.createOrReplaceTempView('neededDates' )\n",
    "\n",
    "# Show the DataFrame\n",
    "dimDate = spark.sql(\"select * from neededDates\")\n",
    "dimDate.show()\n",
    "\n",
    "# Define the path to save the Delta table\n",
    "delta_table_path = \"spark-warehouse/dimDate\"\n",
    "\n",
    "# Save dimDate DataFrame as a Delta table\n",
    "dimDate.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)"
   ],
   "id": "687a2ce94dc1c979",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|calendarDate|dateSK|\n",
      "+------------+------+\n",
      "|  2009-01-01|     0|\n",
      "|  2009-01-02|     1|\n",
      "|  2009-01-03|     2|\n",
      "|  2009-01-04|     3|\n",
      "|  2009-01-05|     4|\n",
      "|  2009-01-06|     5|\n",
      "|  2009-01-07|     6|\n",
      "|  2009-01-08|     7|\n",
      "|  2009-01-09|     8|\n",
      "|  2009-01-10|     9|\n",
      "|  2009-01-11|    10|\n",
      "|  2009-01-12|    11|\n",
      "|  2009-01-13|    12|\n",
      "|  2009-01-14|    13|\n",
      "|  2009-01-15|    14|\n",
      "|  2009-01-16|    15|\n",
      "|  2009-01-17|    16|\n",
      "|  2009-01-18|    17|\n",
      "|  2009-01-19|    18|\n",
      "|  2009-01-20|    19|\n",
      "+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:31:51.974394Z",
     "start_time": "2024-11-03T16:31:51.164202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Creating a Dimension table \"dimdate\"\n",
    "dimDate = spark.sql(\"select dateSK, \\\n",
    "  year(calendarDate) * 10000 + month(calendarDate) * 100 + day(calendarDate) as dateInt, \\\n",
    "  CalendarDate, \\\n",
    "  year(calendarDate) AS CalendarYear, \\\n",
    "  date_format(calendarDate, 'MMMM') as CalendarMonth, \\\n",
    "  month(calendarDate) as MonthOfYear, \\\n",
    "  date_format(calendarDate, 'EEEE') as CalendarDay, \\\n",
    "  dayofweek(calendarDate) AS DayOfWeek, \\\n",
    "  weekday(calendarDate) + 1 as DayOfWeekStartMonday, \\\n",
    "  case \\\n",
    "    when weekday(calendarDate) < 5 then 'Y' \\\n",
    "    else 'N' \\\n",
    "  end as IsWeekDay, \\\n",
    "  dayofmonth(calendarDate) as DayOfMonth, \\\n",
    "  case \\\n",
    "    when calendarDate = last_day(calendarDate) then 'Y' \\\n",
    "    else 'N' \\\n",
    "  end as IsLastDayOfMonth, \\\n",
    "  dayofyear(calendarDate) as DayOfYear, \\\n",
    "  weekofyear(calendarDate) as WeekOfYearIso, \\\n",
    "  quarter(calendarDate) as QuarterOfYear \\\n",
    "from  \\\n",
    "  neededDates \\\n",
    "order by \\\n",
    "  calendarDate\")\n",
    "\n",
    "dimDate.show()"
   ],
   "id": "e268c5f84e511717",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------+------------+-------------+-----------+-----------+---------+--------------------+---------+----------+----------------+---------+-------------+-------------+\n",
      "|dateSK| dateInt|CalendarDate|CalendarYear|CalendarMonth|MonthOfYear|CalendarDay|DayOfWeek|DayOfWeekStartMonday|IsWeekDay|DayOfMonth|IsLastDayOfMonth|DayOfYear|WeekOfYearIso|QuarterOfYear|\n",
      "+------+--------+------------+------------+-------------+-----------+-----------+---------+--------------------+---------+----------+----------------+---------+-------------+-------------+\n",
      "|     0|20090101|  2009-01-01|        2009|      January|          1|   Thursday|        5|                   4|        Y|         1|               N|        1|            1|            1|\n",
      "|     1|20090102|  2009-01-02|        2009|      January|          1|     Friday|        6|                   5|        Y|         2|               N|        2|            1|            1|\n",
      "|     2|20090103|  2009-01-03|        2009|      January|          1|   Saturday|        7|                   6|        N|         3|               N|        3|            1|            1|\n",
      "|     3|20090104|  2009-01-04|        2009|      January|          1|     Sunday|        1|                   7|        N|         4|               N|        4|            1|            1|\n",
      "|     4|20090105|  2009-01-05|        2009|      January|          1|     Monday|        2|                   1|        Y|         5|               N|        5|            2|            1|\n",
      "|     5|20090106|  2009-01-06|        2009|      January|          1|    Tuesday|        3|                   2|        Y|         6|               N|        6|            2|            1|\n",
      "|     6|20090107|  2009-01-07|        2009|      January|          1|  Wednesday|        4|                   3|        Y|         7|               N|        7|            2|            1|\n",
      "|     7|20090108|  2009-01-08|        2009|      January|          1|   Thursday|        5|                   4|        Y|         8|               N|        8|            2|            1|\n",
      "|     8|20090109|  2009-01-09|        2009|      January|          1|     Friday|        6|                   5|        Y|         9|               N|        9|            2|            1|\n",
      "|     9|20090110|  2009-01-10|        2009|      January|          1|   Saturday|        7|                   6|        N|        10|               N|       10|            2|            1|\n",
      "|    10|20090111|  2009-01-11|        2009|      January|          1|     Sunday|        1|                   7|        N|        11|               N|       11|            2|            1|\n",
      "|    11|20090112|  2009-01-12|        2009|      January|          1|     Monday|        2|                   1|        Y|        12|               N|       12|            3|            1|\n",
      "|    12|20090113|  2009-01-13|        2009|      January|          1|    Tuesday|        3|                   2|        Y|        13|               N|       13|            3|            1|\n",
      "|    13|20090114|  2009-01-14|        2009|      January|          1|  Wednesday|        4|                   3|        Y|        14|               N|       14|            3|            1|\n",
      "|    14|20090115|  2009-01-15|        2009|      January|          1|   Thursday|        5|                   4|        Y|        15|               N|       15|            3|            1|\n",
      "|    15|20090116|  2009-01-16|        2009|      January|          1|     Friday|        6|                   5|        Y|        16|               N|       16|            3|            1|\n",
      "|    16|20090117|  2009-01-17|        2009|      January|          1|   Saturday|        7|                   6|        N|        17|               N|       17|            3|            1|\n",
      "|    17|20090118|  2009-01-18|        2009|      January|          1|     Sunday|        1|                   7|        N|        18|               N|       18|            3|            1|\n",
      "|    18|20090119|  2009-01-19|        2009|      January|          1|     Monday|        2|                   1|        Y|        19|               N|       19|            4|            1|\n",
      "|    19|20090120|  2009-01-20|        2009|      January|          1|    Tuesday|        3|                   2|        Y|        20|               N|       20|            4|            1|\n",
      "+------+--------+------------+------------+-------------+-----------+-----------+---------+--------------------+---------+----------+----------------+---------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:31:52.371114Z",
     "start_time": "2024-11-03T16:31:52.044759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#from pyspark.sql.functions import explode, expr, sequence,col, date_format\n",
    "df_SparkSQL = df_SQL \\\n",
    "    .withColumn(\"year\", date_format(\"calendarDate\",'yyyy')) \\\n",
    "    .withColumn(\"month\", date_format(\"calendarDate\",'MMMM')) \\\n",
    "    .withColumn(\"lasyDayOfMonth\" \\\n",
    "                ,expr(\"case when calendarDate = last_day(calendarDate) then 'Y' \\\n",
    "                else 'N' \\\n",
    "                end as IsLastDayOfMonth\"))\n",
    "df_SparkSQL.show() "
   ],
   "id": "b6986cd70672b1e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+----+-------+--------------+\n",
      "|calendarDate|dateSK|year|  month|lasyDayOfMonth|\n",
      "+------------+------+----+-------+--------------+\n",
      "|  2009-01-01|     0|2009|January|             N|\n",
      "|  2009-01-02|     1|2009|January|             N|\n",
      "|  2009-01-03|     2|2009|January|             N|\n",
      "|  2009-01-04|     3|2009|January|             N|\n",
      "|  2009-01-05|     4|2009|January|             N|\n",
      "|  2009-01-06|     5|2009|January|             N|\n",
      "|  2009-01-07|     6|2009|January|             N|\n",
      "|  2009-01-08|     7|2009|January|             N|\n",
      "|  2009-01-09|     8|2009|January|             N|\n",
      "|  2009-01-10|     9|2009|January|             N|\n",
      "|  2009-01-11|    10|2009|January|             N|\n",
      "|  2009-01-12|    11|2009|January|             N|\n",
      "|  2009-01-13|    12|2009|January|             N|\n",
      "|  2009-01-14|    13|2009|January|             N|\n",
      "|  2009-01-15|    14|2009|January|             N|\n",
      "|  2009-01-16|    15|2009|January|             N|\n",
      "|  2009-01-17|    16|2009|January|             N|\n",
      "|  2009-01-18|    17|2009|January|             N|\n",
      "|  2009-01-19|    18|2009|January|             N|\n",
      "|  2009-01-20|    19|2009|January|             N|\n",
      "+------------+------+----+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:31:53.052496Z",
     "start_time": "2024-11-03T16:31:52.423316Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "4c8e3e1caf527eca",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
